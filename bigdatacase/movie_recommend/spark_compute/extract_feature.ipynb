{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "程序员的1 of k编码为: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 1 of k 编码\n",
    "# 特征值为programmer的特征提取\n",
    "from pyspark import SparkContext\n",
    "import numpy as np\n",
    "sc.stop()\n",
    "sc = SparkContext(\"local\")\n",
    "user_data = sc.textFile(\"file:///E:/Code/python_spark/six_cases\"\n",
    "                        \"/movie_lens/data/u.user\")\n",
    "user_fields = user_data.map(lambda x:x.split(\"|\"))\n",
    "all_occupations = user_fields.map(lambda x:x[3]).distinct().collect()\n",
    "\n",
    "all_occupations.sort()\n",
    "\n",
    "idx=0\n",
    "all_occupations_dict = {}\n",
    "for occupation in all_occupations:\n",
    "    all_occupations_dict[occupation]=idx\n",
    "    idx=idx+1\n",
    "K = len(all_occupations_dict)\n",
    "binary_k = np.zeros(K)\n",
    "programmer = all_occupations_dict[\"programmer\"]\n",
    "binary_k[programmer] = 1\n",
    "print(\"程序员的1 of k编码为: %s\" % binary_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, 'afternoon', 'lunch', 'lunch']\n"
     ]
    }
   ],
   "source": [
    "# 派生特征提取\n",
    "rating_data_raw = sc.textFile(\"file:///E:/Code/python_spark/six_cases\"\n",
    "                        \"/movie_lens/data/u.data\")\n",
    "# 获取评分RDD\n",
    "rating_data = rating_data_raw.map(lambda line: line.split(\"\\t\"))\n",
    "ratings = rating_data.map(lambda fields: int(fields[2]))\n",
    "def extract_datatime(x):\n",
    "    import datetime\n",
    "    return datetime.datetime.fromtimestamp(x)\n",
    "timestamps = rating_data.map(lambda x:int(x[3]))\n",
    "hour_of_day = timestamps.map(lambda x:extract_datatime(x).hour)\n",
    "\n",
    "def assign_tod(hr):\n",
    "    times_of_day = {\n",
    "                'morning' : range(7, 12),\n",
    "                'lunch' : range(12, 14),\n",
    "                'afternoon' : range(14, 18),\n",
    "                'evening' : range(18, 23),\n",
    "                'night' : range(23, 7)\n",
    "                }\n",
    "    for k, v in times_of_day.items():\n",
    "        if hr in v: \n",
    "            return k\n",
    " \n",
    "# 获取新的分类变量RDD\n",
    "time_of_day = hour_of_day.map(lambda hr: assign_tod(hr))\n",
    "print(time_of_day.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<1x2645 sparse matrix of type '<class 'numpy.float64'>'\n\twith 2 stored elements in Compressed Sparse Column format>, <1x2645 sparse matrix of type '<class 'numpy.float64'>'\n\twith 1 stored elements in Compressed Sparse Column format>, <1x2645 sparse matrix of type '<class 'numpy.float64'>'\n\twith 2 stored elements in Compressed Sparse Column format>, <1x2645 sparse matrix of type '<class 'numpy.float64'>'\n\twith 2 stored elements in Compressed Sparse Column format>, <1x2645 sparse matrix of type '<class 'numpy.float64'>'\n\twith 1 stored elements in Compressed Sparse Column format>]\n"
     ]
    }
   ],
   "source": [
    "# 文本特征提取\n",
    "movie_data = sc.textFile(\"file:///E:/Code/python_spark/six_cases\"\n",
    "                        \"/movie_lens/data/u.item\")\n",
    "movie_fields = movie_data.map(lambda lines: lines.split(\"|\"))\n",
    " \n",
    "# 函数: 剔除掉标题中的(年份)部分\n",
    "def extract_title(raw):\n",
    "    import re\n",
    "    grps = re.search(\"\\((\\w+)\\)\", raw)\n",
    "    if grps:\n",
    "        return raw[:grps.start()].strip()\n",
    "    else:\n",
    "        return raw\n",
    " \n",
    "# 获取影片名RDD\n",
    "raw_titles = movie_fields.map(lambda fields: fields[1])\n",
    " \n",
    "# 剔除影片名中的(年份)\n",
    "movie_titles = raw_titles.map(lambda m: extract_title(m))\n",
    "title_terms = movie_titles.map(lambda t: t.split(\" \"))\n",
    " \n",
    "# 搜集所有的词\n",
    "all_terms = title_terms.flatMap(lambda x: x).distinct().collect()\n",
    "\n",
    "idx = 0\n",
    "all_terms_dict = {}\n",
    "for term in all_terms:\n",
    "    all_terms_dict[term] = idx\n",
    "    idx +=1\n",
    "num_terms = len(all_terms_dict)\n",
    " \n",
    "# 函数: 采用稀疏向量格式保存编码后的特征并返回\n",
    "def create_vector(terms, term_dict):\n",
    "    from scipy import sparse as sp\n",
    "    x = sp.csc_matrix((1, num_terms))\n",
    "    for t in terms:\n",
    "        if t in term_dict:\n",
    "            idx = term_dict[t]\n",
    "            x[0, idx] = 1\n",
    "    return x\n",
    " \n",
    "# 将字典保存为广播数据格式类型。因为各个worker都要用\n",
    "all_terms_bcast = sc.broadcast(all_terms_dict)\n",
    "# 采用稀疏矩阵格式保存影片名特征\n",
    "term_vectors = title_terms.map(lambda terms: create_vector(terms, all_terms_bcast.value))\n",
    "# 展示提取结果\n",
    "print(term_vectors.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量x:\n[ 0.49671415 -0.1382643   0.64768854  1.52302986 -0.23415337 -0.23413696\n  1.57921282  0.76743473 -0.46947439  0.54256004]\n被MLlib归一化后的向量x:\n[ 0.19172213 -0.05336737  0.24999534  0.58786029 -0.09037871 -0.09037237\n  0.60954584  0.29621508 -0.1812081   0.20941776]\n被MLlib归一化后的向量x的二阶范数: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 归一化特征\n",
    "# 导入Spark库中的正则化类\n",
    "from pyspark.mllib.feature import Normalizer\n",
    "# 初始化正则化对象\n",
    "normalizer = Normalizer()\n",
    "np.random.seed(42)\n",
    "x = np.random.randn(10)\n",
    "vector = sc.parallelize([x])\n",
    "normalized_x_mllib = normalizer.transform(vector).first().toArray()\n",
    "  \n",
    "# 结果展示\n",
    "print(\"向量x:\\n%s\" % x)\n",
    "print(\"被MLlib归一化后的向量x:\\n%s\" % normalized_x_mllib)\n",
    "print(\"被MLlib归一化后的向量x的二阶范数: %2.4f\" % \n",
    "      np.linalg.norm(normalized_x_mllib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
